{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e81c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor output: torch.Size([3, 5, 20])\n",
      "tensor([[[-0.1136, -0.0677,  0.0240, -0.2410, -0.2703, -0.2916, -0.1610,\n",
      "          -0.0403, -0.2039,  0.3268,  0.0936, -0.1283,  0.4434,  0.1891,\n",
      "           0.1537,  0.1830, -0.0283, -0.0970,  0.1833, -0.2228],\n",
      "         [-0.2771,  0.1065, -0.0923,  0.1841, -0.4071, -0.0253, -0.4378,\n",
      "          -0.0659,  0.0220,  0.0691,  0.2979, -0.2294,  0.4487,  0.0480,\n",
      "           0.1620,  0.0849, -0.0809, -0.3667,  0.2824, -0.4627],\n",
      "         [-0.1167,  0.3501,  0.1699, -0.0840, -0.3866, -0.1472, -0.5147,\n",
      "          -0.3408,  0.0582,  0.0045,  0.0642, -0.3626,  0.5542,  0.1922,\n",
      "           0.4794,  0.1559,  0.0337, -0.3902,  0.1412, -0.4100],\n",
      "         [-0.0065,  0.2015, -0.2479, -0.3228, -0.0819, -0.3216, -0.3709,\n",
      "          -0.4735,  0.1980,  0.1359,  0.3047, -0.2625,  0.5946,  0.3553,\n",
      "           0.3621,  0.2191,  0.0708, -0.4177,  0.3053, -0.1882],\n",
      "         [-0.1203,  0.0264,  0.0337,  0.1757, -0.5121, -0.2706, -0.3242,\n",
      "          -0.2235, -0.0763, -0.0206,  0.1703, -0.2933,  0.5744,  0.2194,\n",
      "           0.2106,  0.2586, -0.0441, -0.4111,  0.4500, -0.2853]],\n",
      "\n",
      "        [[-0.0134, -0.2241,  0.1672, -0.2992, -0.0782, -0.2752,  0.0357,\n",
      "          -0.3577, -0.1526,  0.4334,  0.1777, -0.0112,  0.5455,  0.5515,\n",
      "           0.1876,  0.1062,  0.1072, -0.0810,  0.3333,  0.0859],\n",
      "         [-0.0349,  0.0994, -0.2201,  0.0703, -0.4091, -0.3190, -0.1586,\n",
      "           0.3357,  0.1565,  0.0082,  0.3298, -0.2669,  0.2242, -0.1534,\n",
      "           0.2236,  0.3695, -0.0096, -0.2749,  0.3079, -0.5288],\n",
      "         [-0.1047,  0.1035,  0.1187, -0.3086, -0.2327, -0.1452, -0.4714,\n",
      "          -0.5925, -0.1086,  0.4661,  0.4358, -0.0443,  0.7122,  0.5894,\n",
      "           0.2172, -0.1101,  0.0706, -0.1123,  0.2440,  0.0576],\n",
      "         [ 0.0672,  0.1549, -0.3878, -0.2441, -0.4336, -0.4120, -0.1722,\n",
      "           0.1180,  0.2755,  0.1585,  0.1830, -0.0917,  0.2462, -0.0687,\n",
      "           0.1766,  0.3947,  0.2161, -0.5344,  0.2700, -0.2658],\n",
      "         [-0.2504,  0.0617,  0.3712,  0.3014, -0.4245, -0.1007, -0.4542,\n",
      "          -0.4442, -0.3533,  0.2815,  0.3175, -0.2813,  0.6853,  0.4568,\n",
      "           0.2613,  0.0038, -0.0098, -0.1511,  0.3196, -0.2838]],\n",
      "\n",
      "        [[-0.2259, -0.1274,  0.1565, -0.0107, -0.3434, -0.1155, -0.1457,\n",
      "          -0.1595, -0.2586,  0.3455,  0.0919, -0.0756,  0.5459,  0.3072,\n",
      "           0.0897,  0.0163, -0.0691, -0.1590,  0.2370, -0.1434],\n",
      "         [-0.1282, -0.0052, -0.2421, -0.2649, -0.3282,  0.0400, -0.2940,\n",
      "          -0.2485,  0.1612,  0.3395,  0.3155,  0.0734,  0.5130,  0.3395,\n",
      "           0.1578,  0.0658,  0.0409, -0.3863,  0.2691, -0.0461],\n",
      "         [ 0.0311,  0.0737, -0.1095, -0.2689, -0.4419, -0.3249, -0.2997,\n",
      "          -0.1476, -0.0293,  0.1619,  0.1857, -0.1532,  0.3966,  0.1888,\n",
      "           0.2667,  0.3305,  0.1901, -0.2489,  0.2297, -0.2197],\n",
      "         [-0.2611,  0.1712, -0.1513,  0.0829, -0.3950, -0.1707, -0.4378,\n",
      "          -0.2273, -0.1178,  0.1645,  0.3515, -0.1829,  0.5144,  0.1439,\n",
      "           0.2222,  0.1557, -0.0123, -0.2951,  0.2700, -0.3595],\n",
      "         [-0.2036,  0.3956,  0.0205,  0.0412, -0.4338, -0.1783, -0.5714,\n",
      "          -0.1474,  0.0593, -0.1201,  0.0652, -0.3863,  0.4549, -0.0341,\n",
      "           0.3975,  0.2512,  0.0352, -0.4789,  0.1929, -0.5237]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "Last hn: torch.Size([2, 3, 20])\n",
      "tensor([[[-0.0930,  0.1478,  0.3233,  0.3472,  0.1107,  0.1358, -0.1207,\n",
      "          -0.1198,  0.2064,  0.4583, -0.0452,  0.0910,  0.3225, -0.4230,\n",
      "           0.0639,  0.0091,  0.0664,  0.4020,  0.1272, -0.1086],\n",
      "         [-0.1568,  0.0699,  0.5402,  0.2000, -0.0227,  0.0892,  0.0498,\n",
      "          -0.5313,  0.2663,  0.4424, -0.1690, -0.0993,  0.1723, -0.3143,\n",
      "          -0.2813,  0.5395,  0.3005,  0.5630,  0.4705, -0.0923],\n",
      "         [ 0.3606, -0.1744, -0.0014,  0.2633,  0.1946,  0.1365,  0.1523,\n",
      "           0.2445,  0.0764,  0.1525, -0.0286,  0.4634,  0.3351,  0.2567,\n",
      "           0.2379, -0.1275, -0.3222,  0.1447, -0.0617, -0.1432]],\n",
      "\n",
      "        [[-0.1203,  0.0264,  0.0337,  0.1757, -0.5121, -0.2706, -0.3242,\n",
      "          -0.2235, -0.0763, -0.0206,  0.1703, -0.2933,  0.5744,  0.2194,\n",
      "           0.2106,  0.2586, -0.0441, -0.4111,  0.4500, -0.2853],\n",
      "         [-0.2504,  0.0617,  0.3712,  0.3014, -0.4245, -0.1007, -0.4542,\n",
      "          -0.4442, -0.3533,  0.2815,  0.3175, -0.2813,  0.6853,  0.4568,\n",
      "           0.2613,  0.0038, -0.0098, -0.1511,  0.3196, -0.2838],\n",
      "         [-0.2036,  0.3956,  0.0205,  0.0412, -0.4338, -0.1783, -0.5714,\n",
      "          -0.1474,  0.0593, -0.1201,  0.0652, -0.3863,  0.4549, -0.0341,\n",
      "           0.3975,  0.2512,  0.0352, -0.4789,  0.1929, -0.5237]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input_size = 3  # размерность входного вектора\n",
    "hidden_size = 20  # размерность скрытого состояния\n",
    "num_layers = 2   # количество рекуррентных слоёв\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "batch_size = 3\n",
    "seq_length = 5\n",
    "x = torch.randn(batch_size, seq_length, input_size)\n",
    "h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "output, hn = rnn(x, h0)\n",
    "print('Tensor output:', output.shape)\n",
    "print(output)\n",
    "print('Last hn:', hn.shape)\n",
    "print(hn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c932899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2000\n",
    "embedding_dim = 3\n",
    "\n",
    "emb_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "emb_layer_res = emb_layer(torch.tensor([[2, 3, 1523, 7], [123, 46, 56, 2]]))\n",
    "rnn_layer_res = rnn(emb_layer_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ca26a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "lengths = torch.tensor([5, 3, 2])\n",
    "packed_x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "packed_output, hn = rnn(packed_x, None)\n",
    "output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c38a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size dataset's:\n",
      "6500\n",
      "First feedback from dataset:\n",
      "Worst sandwich on Earth.\\nI'd rather eat a dead whore.\\nPlease...never come here.\n",
      "And it's rating:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_csv('/home/user/Загрузки/yelp_reviews.csv')\n",
    "texts = raw['text']\n",
    "labels = raw['label']\n",
    "print(\"Size dataset's:\")\n",
    "print(len(texts))\n",
    "print('First feedback from dataset:')\n",
    "print(texts[0])\n",
    "print(\"And it's rating:\")\n",
    "print(labels[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67be5625",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequence, pack_padded_sequence\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "\n",
    "# загрузка датасета\n",
    "raw = pd.read_csv('yelp_reviews.csv')\n",
    "\n",
    "\n",
    "texts = raw['text']\n",
    "labels = raw['label']\n",
    "\n",
    "\n",
    "# разделение выборки на трейн и тест\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# создание токенизатора с помощью класса AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = # создайте токенизатор\n",
    "\n",
    "\n",
    "# токенизируем тексты\n",
    "train_texts_tokenized = tokenizer(train_texts, truncation=True)['input_ids']\n",
    "val_texts_tokenized = tokenizer(val_texts, truncation=True)['input_ids']\n",
    "\n",
    "\n",
    "# создаём класс кастомного, наследуясь от класса Dataset из PyTorch\n",
    "\n",
    "class YelpDataset(Dataset):\n",
    "    # в конструкторе просто сохраняем тексты и классы\n",
    "    def __init__(self, texts, labels, max_len=256):\n",
    "        self.texts = # сохраните тексты\n",
    "        self.labels = # сохраните классы\n",
    "        self.max_len = # сохрание max_len\n",
    "\n",
    "\n",
    "    # возвращаем размер датасета (кол-во текстов)\n",
    "    def __len__(self):\n",
    "        return # верните размер датасета\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # возвращаем текст и его класс\n",
    "        # для текста ограничиваем длину\n",
    "        # не делаем никаких доп. преобразований как padding и masking\n",
    "        return {\n",
    "            'text': # верните текст под индексом idx в виде тензора, ограничьте его длиной self.max_len\n",
    "            'label': # верните класс под индексом idx в виде тензора\n",
    "        }\n",
    "\n",
    "\n",
    "# кастомная функция collate_fn для формирования батчей\n",
    "def collate_fn(batch):\n",
    "    texts = # получите список текстов в батче\n",
    "    labels = # получите список классов в батче\n",
    "    lengths = # посчитайте список длин текстов в батче \n",
    "    padded_texts = # реализуйте пэддинг для текстов\n",
    "\n",
    "\n",
    "    return {\n",
    "        'input_ids': padded_texts, \n",
    "        'lengths': lengths, \n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "# создаём датасеты\n",
    "train_dataset = YelpDataset(texts=train_texts_tokenized, labels=train_labels)\n",
    "val_dataset = YelpDataset(texts=val_texts_tokenized, labels=val_labels)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# создаём даталоадеры\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "print(f'Количество батчей в train_dataloader: {len(train_dataloader)}')\n",
    "print(f'Количество батчей в val_dataloader: {len(val_dataloader)}')\n",
    "\n",
    "\n",
    "print('Размерности батчей:')\n",
    "for batch in train_dataloader:\n",
    "    print('input_ids:', batch['input_ids'].shape)\n",
    "    print('lengths:', batch['lengths'].shape)\n",
    "    print('labels:', batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f227a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текущий интерпретатор Python: /home/user/Projects/sprint1/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Текущий интерпретатор Python:\", sys.executable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (sprint1)",
   "language": "python",
   "name": "sprint1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
